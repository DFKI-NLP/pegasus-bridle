# Edit these variables according to your need

# choose an Enroot Image
# IMPORTANT: For the scripts provided here to function correctly, there needs to be conda installed in that image!
CONTAINER_IMAGE=/netscratch/enroot/nvcr.io_nvidia_pytorch_21.10-py3.sqsh

# chooses a Slurm partition
PARTITION=RTXA6000-SLT

# resource allocation (RESOURCE_ALLOCATION):
N_TASK=1
GPUS_PER_TASK=1
CPUS_PER_GPU=4
MEMORY_PER_CPU=4G
# assemble everything (feel free to modify this):
RESOURCE_ALLOCATION="--ntasks=$N_TASK --gpus-per-task=$GPUS_PER_TASK --cpus-per-gpu=$CPUS_PER_GPU --mem-per-cpu=$MEMORY_PER_CPU"

# use the current working directory as the working directory inside the container
CONTAINER_WORKDIR=`pwd`

# We mount the following (CONTAINER_MOUNTS):
# * the whole /netscratch, e.g. to keep previously created symlinks into that alive,
# * datasets /ds as readonly,
# * the working directory, $HOST_WORKDIR, which is usually the current working directory, is mapped to the $CONTAINER_WORKDIR,
# * existing conda environments, and
# * we persist any cache locations to $HOST_CACHEDIR.
HOST_WORKDIR=`pwd`
# ensure that this path exists at the host!
HOST_CACHEDIR=/netscratch/$USER/.cache_slurm
# change this if you have installed miniconda to another location
HOST_CONDA_ENVS_DIR=/netscratch/$USER/miniconda3/envs
# change this if you use another Enroot image with a different conda location
CONTAINER_CONDA_ENVS_DIR=/opt/conda/envs
# assemble everything:
CONTAINER_MOUNTS=/netscratch:/netscratch,/ds:/ds:ro,"$HOST_WORKDIR":"$CONTAINER_WORKDIR","$HOST_CONDA_ENVS_DIR":"$CONTAINER_CONDA_ENVS_DIR","$HOST_CACHEDIR":"/home/$USER/.cache","$HOST_CACHEDIR":/root/.cache,"$HOST_CACHEDIR":/home/root/.cache

# use the conda environment that is activated at the host
CONDA_ENV=$CONDA_DEFAULT_ENV
